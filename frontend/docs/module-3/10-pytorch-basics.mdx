---
id: chapter-10-pytorch-basics
title: "Chapter 10: Deep Learning with PyTorch"
description: "Learn PyTorch for building neural networks for robot perception and control."
sidebar_position: 10
module: 3
part: 1
chapter_index: 10
learning_objectives:
  - Understand neural network basics and PyTorch tensors
  - Build convolutional neural networks (CNNs)
  - Train models for image classification
  - Deploy trained models for robot perception
  - Implement real-time inference
prerequisites: [9]
keywords:
  - PyTorch
  - CNN
  - Training
  - Deep learning
---

# Chapter 10: Deep Learning with PyTorch

## PyTorch Basics

```python
import torch
import numpy as np

# Create tensors
t1 = torch.tensor([1, 2, 3])
t2 = torch.randn(3, 3)
t3 = torch.zeros(2, 4)

# Tensor operations
result = t1 + 2
matrix = torch.matmul(t2, t2.T)

# GPU support
if torch.cuda.is_available():
    t = t1.cuda()

# Autograd
x = torch.randn(3, requires_grad=True)
y = x ** 2
z = y.sum()
z.backward()
print(x.grad)
```

## CNN Architecture

```python
import torch.nn as nn
import torch.optim as optim

class RobotVisionCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(RobotVisionCNN, self).__init__()

        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()

        self.fc1 = nn.Linear(128 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))

        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

model = RobotVisionCNN(num_classes=10)
```

## Training Loop

```python
from torchvision import datasets, transforms

# Data loading
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)

# Setup
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Training
for epoch in range(10):
    total_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%")
```

## Transfer Learning

```python
import torchvision.models as models

# Load pre-trained model
model = models.resnet18(pretrained=True)

# Freeze early layers
for param in model.layer1.parameters():
    param.requires_grad = False
for param in model.layer2.parameters():
    param.requires_grad = False

# Replace final layer
model.fc = nn.Linear(512, 5)  # 5 robot classes

# Optimizer
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)
```

## Inference

```python
class RobotObjectDetector:
    def __init__(self, model_path, device='cpu'):
        self.model = RobotVisionCNN()
        self.model.load_state_dict(torch.load(model_path))
        self.model.to(device)
        self.model.eval()
        self.device = device

    def detect(self, image_cv2):
        image_tensor = transforms.ToTensor()(image_cv2).unsqueeze(0).to(self.device)

        with torch.no_grad():
            outputs = self.model(image_tensor)
            prob = torch.softmax(outputs, dim=1)
            class_id = torch.argmax(prob, dim=1).item()
            confidence = prob[0, class_id].item()

        return class_id, confidence

# Real-time detection
detector = RobotObjectDetector('model.pth')

import cv2
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_resized = cv2.resize(frame, (32, 32))
    class_id, conf = detector.detect(frame_resized)

    cv2.putText(frame, f"Class {class_id}: {conf:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow('Detection', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## Model Saving

```python
# Save model
torch.save(model.state_dict(), 'robot_model.pth')

# Save checkpoint
torch.save({
    'model_state': model.state_dict(),
    'optimizer_state': optimizer.state_dict(),
    'epoch': epoch
}, 'checkpoint.pth')

# Load
model.load_state_dict(torch.load('robot_model.pth'))

checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state'])
```

## Summary

| Component | Purpose |
|-----------|---------|
| Tensor | Data structure |
| Module | Layer/Network |
| DataLoader | Batch loading |
| Optimizer | Training |
| Loss | Objective |

## Next Steps

The next chapter covers reinforcement learning for robot decision-making.
