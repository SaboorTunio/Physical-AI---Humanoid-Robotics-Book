---
id: chapter-9-computer-vision
title: "Chapter 9: Computer Vision Fundamentals"
description: "Master computer vision for robotics including image processing, feature detection, and object recognition."
sidebar_position: 9
module: 3
part: 1
chapter_index: 9
learning_objectives:
  - Understand image representation and color spaces
  - Apply image filters and edge detection
  - Detect and match features in images
  - Perform object detection and segmentation
  - Implement real-time video processing
prerequisites: [4, 5]
keywords:
  - Computer vision
  - Image processing
  - OpenCV
  - Feature detection
  - Object detection
---

# Chapter 9: Computer Vision Fundamentals

## Introduction

Computer vision enables robots to perceive and interpret the visual world. This chapter covers fundamental image processing techniques for robot perception.

## Image Processing with OpenCV

```python
import cv2
import numpy as np

# Load image
image = cv2.imread('robot_scene.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Edge detection
edges = cv2.Canny(gray, 100, 200)

# Gaussian blur
blurred = cv2.GaussianBlur(image, (5, 5), 0)

# Display
cv2.imshow('Edges', edges)
cv2.imshow('Blurred', blurred)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## Feature Detection

### SIFT Features

```python
sift = cv2.SIFT_create()
keypoints, descriptors = sift.detectAndCompute(gray, None)

# Draw keypoints
image_sift = cv2.drawKeypoints(gray, keypoints, image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
cv2.imshow('SIFT Features', image_sift)

print(f"Found {len(keypoints)} keypoints")
```

### Feature Matching

```python
img1 = cv2.imread('scene1.jpg', 0)
img2 = cv2.imread('scene2.jpg', 0)

sift = cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

# FLANN matcher
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
search_params = dict(checks=50)

flann = cv2.FlannBasedMatcher(index_params, search_params)
matches = flann.knnMatch(des1, des2, k=2)

# Lowe's ratio test
good_matches = []
for match_pair in matches:
    if len(match_pair) == 2:
        m, n = match_pair
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches[:10], None)
cv2.imshow('Matches', img_matches)
```

## Object Detection

### Color-based Detection

```python
# HSV color space filtering
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
lower_red = np.array([0, 100, 100])
upper_red = np.array([10, 255, 255])

mask = cv2.inRange(hsv, lower_red, upper_red)
result = cv2.bitwise_and(image, image, mask=mask)

# Find contours
contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
for contour in contours:
    if cv2.contourArea(contour) > 500:
        x, y, w, h = cv2.boundingRect(contour)
        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
```

### Contour Analysis

```python
for contour in contours:
    area = cv2.contourArea(contour)
    M = cv2.moments(contour)
    cx = int(M['m10'] / M['m00'])
    cy = int(M['m01'] / M['m00'])

    # Circularity
    perimeter = cv2.arcLength(contour, True)
    circularity = 4 * np.pi * area / (perimeter ** 2)

    print(f"Area: {area}, Center: ({cx}, {cy}), Circularity: {circularity:.2f}")
```

## Real-time Processing

```python
class RobotVisionSystem:
    def __init__(self, camera_id=0):
        self.cap = cv2.VideoCapture(camera_id)

    def process_frame(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            largest = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest)
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

        return frame

    def run(self):
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break

            frame = self.process_frame(frame)
            cv2.imshow('Vision', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        self.cap.release()
        cv2.destroyAllWindows()

vision = RobotVisionSystem()
vision.run()
```

## Summary

| Technique | Purpose |
|-----------|---------|
| Canny | Edge detection |
| SIFT | Feature matching |
| HSV | Color filtering |
| Contour | Object detection |

## Next Steps

The next chapter introduces deep learning with PyTorch for intelligent visual understanding.
